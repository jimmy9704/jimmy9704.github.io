---
---

@article{lee2021plane,
    title     = {Clustering-based plane segmentation neural network for urban scene modeling},
    author    = {Lee, Hongjae and Jung, Jiyoung},
    journal   = {Sensors},
    volume    = {21},
    number    = {24},
    pages     = {8382},
    year      = {2021},
    abstract  = {Urban scene modeling is a challenging but essential task for various applications, such as 3D map generation, city digitization, and AR/VR/metaverse applications. To model man-made structures, such as roads and buildings, which are the major components in general urban scenes, we present a clustering-based plane segmentation neural network using 3D point clouds, called hybrid K-means plane segmentation (HKPS). The proposed method segments unorganized 3D point clouds into planes by training the neural network to estimate the appropriate number of planes in the point cloud based on hybrid K-means clustering. We consider both the Euclidean distance and cosine distance to cluster nearby points in the same direction for better plane segmentation results. Our network does not require any labeled information for training. We evaluated the proposed method using the Virtual KITTI dataset and showed that our method outperforms conventional methods in plane segmentation. Our code is publicly available.},
    abbr      = {Sensors},
    code      = {https://github.com/jimmy9704/plane-segmentation-network},
    earlyaccess={false},
    selected  = {true},
    img_path={assets/img/plane_segmentation.png}
}

@article{lee2022gpsglass,
    title     = {GPS-GLASS: Learning Nighttime Semantic Segmentation Using Daytime Video and GPS data}, 
    author    = {Lee, Hongjae and Han, Changwoo and Jung, Seung-Won},
    journal   = {arXiv},
    year      = {2022},
    abstract  = {Semantic segmentation for autonomous driving should be robust against various in-the-wild environments. Nighttime semantic segmentation is especially challenging due to a lack of annotated nighttime images and a large domain gap from daytime images with sufficient annotation. In this paper, we propose a novel GPS-based training framework for nighttime semantic segmentation. Given GPS-aligned pairs of daytime and nighttime images, we perform cross-domain correspondence matching to obtain pixel-level pseudo supervision. Moreover, we conduct flow estimation between daytime video frames and apply GPS-based scaling to acquire another pixel-level pseudo supervision. Using these pseudo supervisions with a confidence map, we train a nighttime semantic segmentation network without any annotation from nighttime images. Experimental results demonstrate the effectiveness of the proposed method on several nighttime semantic segmentation datasets.},
    abbr      = {arXiv},
    code      = {https://github.com/jimmy9704/GPS-GLASS},
    selected  = {true},
    arxiv     = {https://arxiv.org/abs/2207.13297},
    img_path  = {assets/img/gps_glass.png}
}
